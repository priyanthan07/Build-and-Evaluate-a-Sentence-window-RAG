{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files = [\"introduction-to-natural-language-processing.pdf\"]).load_data()\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "\n",
    "def get_sentence_window_index(document, index_dir, sentence_window_size=3):\n",
    "    Node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_sentence\",\n",
    "    )\n",
    "\n",
    "    Settings.llm = OpenAI()\n",
    "    Settings.embed_model = \"local:BAAI/bge-small-en-v1.5\"\n",
    "    Settings.node_parser = Node_parser\n",
    "\n",
    "    if not os.path.exists(index_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents([document])\n",
    "        sentence_index.storage_context.persist(persist_dir=index_dir)\n",
    "        \n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=index_dir))\n",
    "    return sentence_index\n",
    "\n",
    "def get_sentence_window_engine(sentence_index):\n",
    "    \n",
    "    postprocessor = MetadataReplacementPostProcessor(target_metadata_key=\"window\",)\n",
    "    rerank = SentenceTransformerRerank(top_n=2, model=\"BAAI/bge-reranker-base\") \n",
    "    sentence_window_engine = sentence_index.as_query_engine(similarity_top_k=6, node_postprocessors=[postprocessor, rerank])\n",
    "    \n",
    "    return sentence_window_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dir = \"./sentence_index_2\"\n",
    "sw_index_2 = get_sentence_window_index(document, index_dir, sentence_window_size=3)\n",
    "sw_engine_2 = get_sentence_window_engine(sw_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corpora are used in grammatical research to provide data for analysis alongside linguistic research and subjective intuitions of language experts. Recent advancements in computational power and tools have enabled researchers to conduct quantitative studies on various aspects of grammar, such as the frequency of different clause types in English. These tools have also facilitated the testing of predictions made by formal grammars developed within the generative school of linguistics.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_response_2 = sw_engine_2.query(\n",
    "    \"How are corpora utilized in grammatical research, and what advancements have been made with the use of computational tools?\"\n",
    ")\n",
    "window_response_2.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "from trulens_eval import TruLlama\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval.app import App\n",
    "import numpy as np\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI()\n",
    "\n",
    "# Select context to be used in feedback. The location of context is app specific.\n",
    "\n",
    "def get_evaluation_response(rag_engine, app_id, eval_questions):\n",
    "    \n",
    "    context = App.select_context(rag_engine)\n",
    "\n",
    "    # Define a groundedness feedback function\n",
    "    f_groundedness = (\n",
    "        Feedback(provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
    "        .on(context.collect())  # Collect context chunks into a list\n",
    "        .on_output()\n",
    "    )\n",
    "\n",
    "    # Question/answer relevance between overall question and answer.\n",
    "    f_answer_relevance = (\n",
    "        Feedback(provider.relevance, name=\"Answer Relevance\")\n",
    "        .on_input_output()\n",
    "    )\n",
    "\n",
    "    # Question/statement relevance between question and each context chunk.\n",
    "    f_context_relevance = (\n",
    "        Feedback(provider.context_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "        .on_input()\n",
    "        .on(context)\n",
    "        .aggregate(np.mean)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize the recorder\n",
    "    tru_query_engine_recorder = TruLlama(\n",
    "        rag_engine,\n",
    "        app_id= app_id,\n",
    "        feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance])\n",
    "    \n",
    "    for question in eval_questions:\n",
    "        with tru_query_engine_recorder as recording:\n",
    "            response = rag_engine.query(question)\n",
    "    records = recording.get()\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.calls[-1].rets.source_nodes[:].node.text.collect() .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input context will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "eval_questions = [\n",
    "    \"Who introduced the notions of finite-state machines and context-free grammar (CFG) to linguistics?\",\n",
    "    \"How did linguists test formal rules of grammar according to Chomskyâ€™s approach?\",\n",
    "    \"What has contributed to making the vision of computers understanding ordinary language and holding conversations with humans more plausible in the 21st century?\",\n",
    "    \"Why is it often necessary to assign a part of speech (POS) to a word based on its function in context rather than its inherent meaning?\",\n",
    "    \"What are the three fundamental concepts in regular expressions (REs) that are also characteristic of finite-state machines?\",\n",
    "    \"What is the difference between right-linear and left-linear grammars in terms of finite-state machines?\",\n",
    "    \"Why is center-embedding significant in grammars, and what does it allow?\",\n",
    "    \"What is a corpus in the context of natural language processing, and what are the three broad categories of corpora?\",\n",
    "    \"How are corpora used in modern lexicography, and how do they influence dictionary entries?\",\n",
    "    \"How are corpora utilized in grammatical research, and what advancements have been made with the use of computational tools?\"\n",
    "]\n",
    "\n",
    "records = get_evaluation_response(\n",
    "    sw_engine_2,\n",
    "    app_id='sentence window engine 2',\n",
    "    eval_questions = eval_questions\n",
    ")\n",
    "\n",
    "display(records)\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
