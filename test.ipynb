{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.core.indices.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files = [\"introduction-to-natural-language-processing.pdf\"]).load_data()\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "\n",
    "def get_sentence_window_index(documents, index_dir, sentence_window_size=3):\n",
    "    Node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=3,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_sentence\",\n",
    "    )\n",
    "\n",
    "    Settings.llm = OpenAI()\n",
    "    Settings.embed_model = \"local:BAAI/bge-small-en-v1.5\"\n",
    "    Settings.node_parser = Node_parser\n",
    "\n",
    "    if not os.path.exists(index_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents([document])\n",
    "        sentence_index.storage_context.persist(persist_dir=index_dir)\n",
    "        \n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=index_dir))\n",
    "    return sentence_index\n",
    "\n",
    "def get_sentence_window_engine(sentence_index):\n",
    "    \n",
    "    postprocessor = MetadataReplacementPostProcessor(target_metadata_key=\"window\",)\n",
    "    rerank = SentenceTransformerRerank(top_n=2, model=\"BAAI/bge-reranker-base\") \n",
    "    sentence_window_engine = sentence_index.as_query_engine(similarity_top_k=6, node_postprocessors=[postprocessor, rerank])\n",
    "    \n",
    "    return sentence_window_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dir = \"./sentence_index_1\"\n",
    "sw_index_1 = get_sentence_window_index(documents, index_dir, sentence_window_size=1)\n",
    "sw_engine_1 = get_sentence_window_engine(sw_index_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval import Feedback\n",
    "from trulens_eval.app import App\n",
    "import numpy as np\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "# Initialize provider class\n",
    "provider = OpenAI()\n",
    "\n",
    "# Select context to be used in feedback. The location of context is app specific.\n",
    "\n",
    "def get_evaluation_response(rag_engine, app_id, eval_questions):\n",
    "    \n",
    "    context = App.select_context(rag_engine)\n",
    "\n",
    "    # Define a groundedness feedback function\n",
    "    f_groundedness = (\n",
    "        Feedback(provider.groundedness_measure_with_cot_reasons)\n",
    "        .on(context.collect())  # Collect context chunks into a list\n",
    "        .on_output()\n",
    "    )\n",
    "\n",
    "    # Question/answer relevance between overall question and answer.\n",
    "    f_answer_relevance = (\n",
    "        Feedback(provider.relevance)\n",
    "        .on_input_output()\n",
    "    )\n",
    "\n",
    "    # Question/statement relevance between question and each context chunk.\n",
    "    f_context_relevance = (\n",
    "        Feedback(provider.context_relevance_with_cot_reasons)\n",
    "        .on_input()\n",
    "        .on(context)\n",
    "        .aggregate(np.mean)\n",
    "    )\n",
    "\n",
    "    from trulens_eval import TruLlama\n",
    "\n",
    "    # Initialize the recorder\n",
    "    tru_query_engine_recorder = TruLlama(\n",
    "        rag_engine,\n",
    "        app_id= app_id,\n",
    "        feedbacks=[f_groundedness, f_answer_relevance, f_context_relevance])\n",
    "    \n",
    "    for question in eval_questions:\n",
    "        with tru_query_engine_recorder as recording:\n",
    "            response = rag_engine.query(question)\n",
    "    records = recording.get()\n",
    "    \n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"Who introduced the notions of finite-state machines and context-free grammar (CFG) to linguistics?\",\n",
    "    \"How did linguists test formal rules of grammar according to Chomsky’s approach?\",\n",
    "    \"What has contributed to making the vision of computers understanding ordinary language and holding conversations with humans more plausible in the 21st century?\",\n",
    "    \"Why is it often necessary to assign a part of speech (POS) to a word based on its function in context rather than its inherent meaning?\"\n",
    "]\n",
    "\n",
    "records = get_evaluation_response(\n",
    "    sw_engine_1,\n",
    "    app_id='sentence window engine 1',\n",
    "    eval_questions = eval_questions\n",
    ")\n",
    "\n",
    "display(records)\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## window size 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dir = \"./sentence_index_2\"\n",
    "sw_index_2 = get_sentence_window_index(documents, index_dir, sentence_window_size=3)\n",
    "sw_engine_2 = get_sentence_window_engine(sw_index_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"Who introduced the notions of finite-state machines and context-free grammar (CFG) to linguistics?\",\n",
    "    \"How did linguists test formal rules of grammar according to Chomsky’s approach?\",\n",
    "    \"What has contributed to making the vision of computers understanding ordinary language and holding conversations with humans more plausible in the 21st century?\",\n",
    "    \"Why is it often necessary to assign a part of speech (POS) to a word based on its function in context rather than its inherent meaning?\"\n",
    "]\n",
    "\n",
    "records = get_evaluation_response(\n",
    "    sw_engine_2,\n",
    "    app_id='sentence window engine 2',\n",
    "    eval_questions = eval_questions\n",
    ")\n",
    "\n",
    "display(records)\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from trulens.core import TruSession\n",
    "\n",
    "session = TruSession()\n",
    "session.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
